import streamlit as st
from langchain.llms import OpenAI
from langchain import PromptTemplate
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

import os
from dotenv import load_dotenv

load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")

st.title("Summariser App")
st.write("#### Generated by an Open AI GPT3.5 LLM")

prompt = PromptTemplate(
    input_variables=["input"],
template="Please summarize the following text: {input}",
)

#Â Loading the OpenAI's LLM
def load_llm():
    llm = OpenAI()
    return llm

def get_answer(question):
    llm = load_llm()
    final_prompt = prompt.format(input=question)
    with st.spinner("Summarising the content.."):
        st.info(llm(final_prompt))
        st.balloons()


with st.form("summary_form"):
    text = st.text_area("Paste the text here to summarise it:", value="", max_chars=5000)

    submitted = st.form_submit_button("Submit")
    if submitted:
        get_answer(text)